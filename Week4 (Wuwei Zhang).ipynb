{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week4 (Wuwei Zhang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mnist import MNIST\n",
    "\n",
    "def load_dataset():\n",
    "    mndata = MNIST('C:/Users/Zhang/python-mnist/data')\n",
    "    A_train, labels_train = map(np.array, mndata.load_training()) \n",
    "    A_test, labels_test = map(np.array, mndata.load_testing()) \n",
    "    A_train = A_train/255.0\n",
    "    A_test = A_test/255.0\n",
    "    \n",
    "    return A_train, A_test, labels_train, labels_test\n",
    "\n",
    "A_train, A_test, labels_train, labels_test = load_dataset()\n",
    "\n",
    "\n",
    "B_labels_train = np.zeros((60000, 10))\n",
    "for i in range(len(labels_train)):\n",
    "    B_labels_train[i, labels_train[i]] = 1\n",
    "B_labels_test = np.zeros((10000, 10))\n",
    "for j in range(len(labels_test)):\n",
    "    B_labels_test[j, labels_test[j]] = 1\n",
    "    \n",
    "\n",
    "\n",
    "# Create Binary Classification Dataset   \n",
    "\n",
    "ind2 = np.where(labels_train == 2)[0]\n",
    "ind7 = np.where(labels_train ==7)[0]\n",
    "\n",
    "bin_A_train = np.vstack((A_train[ind2,:], A_train[ind7,:]))\n",
    "bin_label_train = np.hstack((-1*np.ones(len(ind2)), np.ones(len(ind7))))\n",
    "\n",
    "\n",
    "ind2_test = np.where(labels_test == 2)[0]\n",
    "ind7_test = np.where(labels_test ==7)[0]\n",
    "\n",
    "bin_A_test = np.vstack((A_test[ind2_test,:], A_test[ind7_test,:]))\n",
    "bin_label_test = np.hstack((-1*np.ones(len(ind2_test)), np.ones(len(ind7_test))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f63a4b55da61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m xfinal, yfinal, J_value_train = grad_descent(np.zeros(784).T, 0, J_grad_x, \n\u001b[0m\u001b[0;32m     69\u001b[0m                                              J_grad_y, step_size = 1e-3)  \n",
      "\u001b[1;32m<ipython-input-3-f63a4b55da61>\u001b[0m in \u001b[0;36mgrad_descent\u001b[1;34m(xinit, yinit, J_grad_x, J_grad_y, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mJ_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[1;32mwhile\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mxnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxold\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mJ_grad_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mynew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myold\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mJ_grad_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# %% Minimize J(x,y) using gradient descent\n",
    "\n",
    "# Define err = $\\eta||x_{t+1} - x_t||_2 + \\eta|y_{t+1} - y|$\n",
    "\n",
    "def mu_i(x, y, i):\n",
    "    return 1/(1 + np.exp((-1)*bin_label_train[i]*(y+bin_A_train[i,]@x)))\n",
    "\n",
    "              \n",
    "def J_grad_x(x, y):\n",
    "    s = np.zeros(784)\n",
    "    for i in range(12223):\n",
    "        s1 = (-1)*bin_label_train[i]*(bin_A_train[i,])*(1-mu_i(x, y, i))\n",
    "        s = np.add(s, s1)\n",
    "    return s / 12223 + 0.01 * 2 * x\n",
    "\n",
    "\n",
    "def J_grad_y(x, y):\n",
    "    s = np.zeros(784)\n",
    "    for i in range(12223):\n",
    "        s1 = (-1)*bin_label_train[i]*(1-mu_i(x, y, i))\n",
    "        s = np.add(s, s1)\n",
    "    return s / 12223\n",
    "\n",
    "\n",
    "def J(x, y):\n",
    "    s = 0;\n",
    "    for i in range(12223):\n",
    "        s1 = 1 + np.exp((-1)*bin_label_train[i]*(y+bin_A_train[i,]@x))\n",
    "        s = s + np.log(s1)\n",
    "    return s / 12223 + 0.01 * np.square(x).sum()/784\n",
    "\n",
    "\n",
    "def grad_descent(xinit, yinit, J_grad_x, J_grad_y, **kwargs):\n",
    "    tol = kwargs.pop('error', 1e-6)\n",
    "    step_size = kwargs.pop('step_size', .1)\n",
    "    \n",
    "    err = 1\n",
    "    xold = xinit\n",
    "    yold = yinit\n",
    "    \n",
    "    max_iter = 5000\n",
    "    iter_count = 0\n",
    "    \n",
    "    J_value = J(xold, yold)\n",
    "    \n",
    "    while err > tol:\n",
    "        xnew = xold - step_size*J_grad_x(xold, yold)\n",
    "        ynew = yold - step_size*J_grad_y(xnew, yold)\n",
    "        \n",
    "        err1 = step_size * np.linalg.norm(xnew - xold,2)\n",
    "        err2 = step_size * abs(ynew - yold)\n",
    "        err = np.squeeze(err1+err2)\n",
    "        \n",
    "        np.append(J_value, J(xnew, ynew))\n",
    "        \n",
    "        iter_count+=1\n",
    "        if iter_count>=max_iter:\n",
    "            print('Reached max number of iterations')\n",
    "            return xnew, ynew, J_value\n",
    "        \n",
    "    return xnew, ynew, J_value\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "xfinal, yfinal, J_value_train = grad_descent(np.zeros(784).T, 0, J_grad_x, \n",
    "                                             J_grad_y, step_size = 1e-3)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
